!pip install streamlit

!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip

!unzip ngrok-stable-linux-amd64.zip

get_ipython().system_raw('./ngrok authtoken 2GbX5vtbLksSzJmvraeyTFKScDE_4dDDVLgiXpS4dNYKtFPmN')

get_ipython().system_raw('./ngrok http 8501 &')

!curl -s http://localhost:4040/api/tunnels | python3 -c \
    'import sys, json; print("Execute the next cell and the go to the following URL: " +json.load(sys.stdin)["tunnels"][0]["public_url"])'

%%writefile nyc.py
import streamlit as st
import pandas as pd
import numpy as np

st.title('Cicle Rides in NYC')

DATE_COLUMN = 'started_at'
DATA_URL = ('/content/citibike-tripdata.csv')

@st.cache
def load_data(nrows):
    data = pd.read_csv(DATA_URL, nrows=nrows)
    lowercase = lambda x: str(x).lower()
    data.rename({'start_lat': 'lat', 'start_lng': 'lon'}, axis=1, inplace=True)
    data[DATE_COLUMN] = pd.to_datetime(data[DATE_COLUMN])
    return data

data_load_state = st.text('Loading cicle nyc data...')
data = load_data(1000)
data_load_state.text("Done! (using st.cache)")

if st.sidebar.checkbox('Show raw data'):
    st.subheader('Raw data')
    st.write(data)

if st.sidebar.checkbox('Recorridos por hora'):
    st.subheader('Numero de recorridos por hora')

    hist_values = np.histogram(data[DATE_COLUMN].dt.hour, bins=24, range=(0,24))[0]
    st.bar_chart(hist_values)


# Some number in the range 0-23
hour_to_filter = st.slider('hour', 0, 23, 17)
filtered_data = data[data[DATE_COLUMN].dt.hour == hour_to_filter]

st.subheader('Map of all pickups at %s:00' % hour_to_filter)
st.map(filtered_data)

!streamlit run /content/nyc.py

get_ipython().system_raw('./ngrok http 8501 &')

!curl -s http://localhost:4040/api/tunnels | python3 -c \
    'import sys, json; print("Execute the next cell and the go to the following URL: " +json.load(sys.stdin)["tunnels"][0]["public_url"])'

%%writefile netflix.py
import streamlit as st
import pandas as pd
import numpy as np



st.title('Netflix app')

DATE_COLUMN = 'released'
DATA_URL = ('movies.csv')

import codecs

@st.cache
def load_data(nrows):
    doc = codecs.open('/content/movies.csv','rU','latin1')
    data = pd.read_csv(doc, nrows=nrows)
    lowercase = lambda x: str(x).lower()
    return data

def filter_data_by_filme(filme):
    filtered_data_filme = data[data['name'].str.upper().str.contains(filme)]
    return filtered_data_filme

def filter_data_by_director(director):
    filtered_data_director = data[data['director'] == director]
    return filtered_data_director


data_load_state = st.text('Loading cicle nyc data...')
data = load_data(1000)
data_load_state.text("Done! (using st.cache)")

if st.sidebar.checkbox('Mostrar todos los filmes'):
    st.subheader('Todos los filmes')
    st.write(data)


titulofilme = st.sidebar.text_input('Titulo del filme :')
btnBuscar = st.sidebar.button('Buscar filmes')

if (btnBuscar):
   data_filme = filter_data_by_filme(titulofilme.upper())
   count_row = data_filme.shape[0]  # Gives number of rows
   st.write(f"Total filmes mostrados : {count_row}")
   st.write(data_filme)



selected_director = st.sidebar.selectbox("Seleccionar Director", data['director'].unique())
btnFilterbyDirector = st.sidebar.button('Filtrar director ')

if (btnFilterbyDirector):
   filterbydir = filter_data_by_director(selected_director)
   count_row = filterbydir.shape[0]  # Gives number of rows
   st.write(f"Total filmes : {count_row}")

   st.dataframe(filterbydir)



!streamlit run /content/netflix.py
